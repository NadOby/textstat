{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!pip install -r requrements.txt\n",
    "# coding: utf-8\n",
    "import nltk\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, save_npz, load_npz, lil_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from string import punctuation\n",
    "from collections import OrderedDict\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_check = sorted([\n",
    "    'любой', 'человек'\n",
    "])\n",
    "\n",
    "soften = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpz_file = 'book_mm.npz'\n",
    "M_learned = load_npz(mpz_file)\n",
    "lemm_learned = open('lemlist.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"russian\")\n",
    "\n",
    "lemm_check = sorted([stemmer.stem(word) for word in words_check])\n",
    "\n",
    "word_match = {}\n",
    "for i in words_check:\n",
    "    word_match[stemmer.stem(i)] = i\n",
    "\n",
    "new_lem = list(sorted(set(lemm_check) & set(lemm_learned)))\n",
    "\n",
    "print(word_match)\n",
    "print(lemm_check)\n",
    "print(new_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = len(lemm_check)\n",
    "M = np.ndarray((order, order))\n",
    "for i in lemm_check:\n",
    "    #print(i)\n",
    "    x_new = lemm_check.index(i)\n",
    "    if i in new_lem:\n",
    "        x_learn = lemm_learned.index(i)\n",
    "        for j in lemm_check:\n",
    "            if j in new_lem:\n",
    "                y_new = lemm_check.index(j)\n",
    "                y_learn = lemm_learned.index(j)\n",
    "                #print(\"new coord: {} {} , old coord: {} {}\".format(x_new, y_new, x_learn, y_learn))\n",
    "                M[x_new, y_new] = M_learned[x_learn, y_learn]\n",
    "            else:\n",
    "                pass\n",
    "    else:\n",
    "        #print(i)\n",
    "        M[x_new,:] = [1/order for x in range(order)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in set(np.where(M == 0)[0]):\n",
    "    M[i,:] += soften\n",
    "\n",
    "#with np.nditer(M, op_flags=['readwrite']) as items:\n",
    "#    for i in items:\n",
    "#        if i == 0:\n",
    "#            i[...] += 1.0e-10\n",
    "M_normalized = normalize(M, norm='l1', axis=1, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for a in lemm_check:\n",
    "#    arr = [x for x in M[lemm_check.index(a)].flat]\n",
    "#    print(a,len(arr), type(arr) ,arr)\n",
    "#print('')    \n",
    "#for b in lemm_check:\n",
    "#    arr = [x for x in M_normalized[lemm_check.index(b)].flat]\n",
    "#    print(b,len(arr), type(arr) ,arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence(mat, depth, lemms, curword=None, final=[], words=None):\n",
    "    if depth != 0:\n",
    "        depth -= 1\n",
    "        if not curword:\n",
    "            nextword = np.random.choice(lemms)\n",
    "        else:\n",
    "            arr = [x for x in  mat[lemms.index(curword)].flat]\n",
    "            #nextword=curword\n",
    "            nextword=np.random.choice(lemms,p=arr)\n",
    "            final.append(words[nextword])\n",
    "\n",
    "        sentence(mat, depth, lemms, nextword, final, words)\n",
    "    return(' '.join(final))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(50):\n",
    "    print(sentence(M_normalized, 16, lemm_check, final=[], words=word_match))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
